"""
æ•°æ®å¯è§†åŒ–åº”ç”¨ï¼šå±•ç¤ºæ•°æ®æ”¶é›†å’Œé¢„å¤„ç†çš„ç»“æœ
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
import json
import os

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="ä¸­æ³•æ•°å­—åŒ–è½¬å‹æ•°æ®åˆ†æ",
    page_icon="ğŸ“Š",
    layout="wide"
)

# è®¾ç½®æ ‡é¢˜
st.title("ä¸­æ³•æ•°å­—åŒ–è½¬å‹æ•°æ®åˆ†æä»ªè¡¨æ¿")

# è·å–æ•°æ®ç›®å½•
DATA_DIR = Path(__file__).parent.parent.parent / "data"
PROCESSED_DATA_DIR = DATA_DIR / "processed"

# åŠ è½½è¯­æ–™åº“ç»Ÿè®¡ä¿¡æ¯
@st.cache_data
def load_corpus_stats():
    stats_file = PROCESSED_DATA_DIR / "corpus_stats.json"
    if stats_file.exists():
        with open(stats_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None

# åŠ è½½è¯­æ–™åº“æ±‡æ€»
@st.cache_data
def load_corpus_summary():
    summary_file = PROCESSED_DATA_DIR / "corpus_summary.csv"
    if summary_file.exists():
        return pd.read_csv(summary_file)
    return None

# åŠ è½½metadataæ–‡ä»¶
@st.cache_data
def load_metadata(metadata_path):
    try:
        with open(metadata_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        return None

# åŠ è½½txtæ–‡ä»¶
@st.cache_data
def load_txt(txt_path):
    try:
        with open(txt_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        return None

# åŠ è½½æ•°æ®
stats = load_corpus_stats()
df = load_corpus_summary()

if stats is None or df is None:
    st.error("æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®æ”¶é›†å’Œé¢„å¤„ç†ç¨‹åºã€‚")
else:
    # åˆ›å»ºä¸‰åˆ—å¸ƒå±€
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("æ€»æ–‡æ¡£æ•°", stats['total_documents'])
    
    with col2:
        st.metric("æ€»è¯æ•°", stats['total_tokens'])
    
    with col3:
        st.metric("æ€»å¥å­æ•°", stats['total_sentences'])
    
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
    col1, col2 = st.columns(2)
    
    with col1:
        # æŒ‰å›½å®¶åˆ†å¸ƒçš„æ–‡æ¡£æ•°
        country_counts = pd.DataFrame(
            list(stats['documents_by_country'].items()),
            columns=['å›½å®¶', 'æ–‡æ¡£æ•°']
        )
        fig_country = px.bar(
            country_counts,
            x='å›½å®¶',
            y='æ–‡æ¡£æ•°',
            title='æŒ‰å›½å®¶åˆ†å¸ƒçš„æ–‡æ¡£æ•°'
        )
        st.plotly_chart(fig_country, use_container_width=True)
    
    with col2:
        # æŒ‰é¢†åŸŸåˆ†å¸ƒçš„æ–‡æ¡£æ•°
        sector_counts = pd.DataFrame(
            list(stats['documents_by_sector'].items()),
            columns=['é¢†åŸŸ', 'æ–‡æ¡£æ•°']
        )
        fig_sector = px.bar(
            sector_counts,
            x='é¢†åŸŸ',
            y='æ–‡æ¡£æ•°',
            title='æŒ‰é¢†åŸŸåˆ†å¸ƒçš„æ–‡æ¡£æ•°'
        )
        st.plotly_chart(fig_sector, use_container_width=True)
    
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
    col1, col2 = st.columns(2)
    
    with col1:
        # æŒ‰è¯­è¨€åˆ†å¸ƒçš„æ–‡æ¡£æ•°
        language_counts = pd.DataFrame(
            list(stats['documents_by_language'].items()),
            columns=['è¯­è¨€', 'æ–‡æ¡£æ•°']
        )
        fig_lang = px.pie(
            language_counts,
            values='æ–‡æ¡£æ•°',
            names='è¯­è¨€',
            title='æŒ‰è¯­è¨€åˆ†å¸ƒçš„æ–‡æ¡£æ•°'
        )
        st.plotly_chart(fig_lang, use_container_width=True)
    
    with col2:
        # å¹³å‡è¯æ•°å’Œå¥å­æ•°
        fig_avg = go.Figure()
        fig_avg.add_trace(go.Bar(
            name='å¹³å‡è¯æ•°',
            x=['å¹³å‡'],
            y=[stats['average_tokens_per_document']]
        ))
        fig_avg.add_trace(go.Bar(
            name='å¹³å‡å¥å­æ•°',
            x=['å¹³å‡'],
            y=[stats['average_sentences_per_document']]
        ))
        fig_avg.update_layout(title='æ–‡æ¡£å¹³å‡è¯æ•°å’Œå¥å­æ•°')
        st.plotly_chart(fig_avg, use_container_width=True)
    
    # è¯¦ç»†æ•°æ®åˆ†æ
    st.header("è¯¦ç»†æ•°æ®åˆ†æ")
    
    # åˆ›å»ºé€‰é¡¹å¡
    tab1, tab2, tab3 = st.tabs(["æŒ‰å›½å®¶åˆ†æ", "æŒ‰é¢†åŸŸåˆ†æ", "æŒ‰è¯­è¨€åˆ†æ"])
    
    with tab1:
        # æŒ‰å›½å®¶åˆ†æ
        country_analysis = df.groupby('country').agg({
            'token_count': ['count', 'sum', 'mean'],
            'filtered_token_count': ['sum', 'mean'],
            'sentence_count': ['sum', 'mean']
        }).round(2)
        country_analysis.columns = ['æ–‡æ¡£æ•°', 'æ€»è¯æ•°', 'å¹³å‡è¯æ•°', 'æ€»è¿‡æ»¤åè¯æ•°', 'å¹³å‡è¿‡æ»¤åè¯æ•°', 'æ€»å¥å­æ•°', 'å¹³å‡å¥å­æ•°']
        st.dataframe(country_analysis)
        
        # æŒ‰å›½å®¶-é¢†åŸŸåˆ†å¸ƒ
        country_sector = pd.crosstab(df['country'], df['sector'])
        fig_country_sector = px.bar(
            country_sector,
            title='å„å›½å„é¢†åŸŸæ–‡æ¡£åˆ†å¸ƒ'
        )
        st.plotly_chart(fig_country_sector, use_container_width=True)
    
    with tab2:
        # æŒ‰é¢†åŸŸåˆ†æ
        sector_analysis = df.groupby('sector').agg({
            'token_count': ['count', 'sum', 'mean'],
            'filtered_token_count': ['sum', 'mean'],
            'sentence_count': ['sum', 'mean']
        }).round(2)
        sector_analysis.columns = ['æ–‡æ¡£æ•°', 'æ€»è¯æ•°', 'å¹³å‡è¯æ•°', 'æ€»è¿‡æ»¤åè¯æ•°', 'å¹³å‡è¿‡æ»¤åè¯æ•°', 'æ€»å¥å­æ•°', 'å¹³å‡å¥å­æ•°']
        st.dataframe(sector_analysis)
        
        # æŒ‰é¢†åŸŸ-è¯­è¨€åˆ†å¸ƒ
        sector_lang = pd.crosstab(df['sector'], df['language'])
        fig_sector_lang = px.bar(
            sector_lang,
            title='å„é¢†åŸŸè¯­è¨€åˆ†å¸ƒ'
        )
        st.plotly_chart(fig_sector_lang, use_container_width=True)
    
    with tab3:
        # æŒ‰è¯­è¨€åˆ†æ
        language_analysis = df.groupby('language').agg({
            'token_count': ['count', 'sum', 'mean'],
            'filtered_token_count': ['sum', 'mean'],
            'sentence_count': ['sum', 'mean']
        }).round(2)
        language_analysis.columns = ['æ–‡æ¡£æ•°', 'æ€»è¯æ•°', 'å¹³å‡è¯æ•°', 'æ€»è¿‡æ»¤åè¯æ•°', 'å¹³å‡è¿‡æ»¤åè¯æ•°', 'æ€»å¥å­æ•°', 'å¹³å‡å¥å­æ•°']
        st.dataframe(language_analysis)
        
        # æŒ‰è¯­è¨€-å›½å®¶åˆ†å¸ƒ
        lang_country = pd.crosstab(df['language'], df['country'])
        fig_lang_country = px.bar(
            lang_country,
            title='å„è¯­è¨€å›½å®¶åˆ†å¸ƒ'
        )
        st.plotly_chart(fig_lang_country, use_container_width=True)
    
    # æ–‡æ¡£è¯¦æƒ…
    st.header("æ–‡æ¡£è¯¦æƒ…")
    
    # åˆ›å»ºæ–‡æ¡£é€‰æ‹©å™¨
    selected_doc = st.selectbox(
        "é€‰æ‹©è¦æŸ¥çœ‹çš„æ–‡æ¡£",
        df['metadata_path'].tolist(),
        format_func=lambda x: os.path.basename(x)
    )
    
    if selected_doc:
        # è·å–å¯¹åº”çš„txtæ–‡ä»¶è·¯å¾„
        txt_path = selected_doc.replace('metadata.json', 'processed.txt')
        
        # åŠ è½½metadataå’Œtxtå†…å®¹
        metadata = load_metadata(selected_doc)
        txt_content = load_txt(txt_path)
        
        if metadata:
            st.subheader("æ–‡æ¡£å…ƒä¿¡æ¯")
            st.json(metadata)
        
        if txt_content:
            st.subheader("æ–‡æ¡£å†…å®¹")
            st.text_area("", txt_content, height=400)
    
    # æ·»åŠ æ—¶é—´ä¿¡æ¯
    st.sidebar.subheader("æ•°æ®ä¿¡æ¯")
    st.sidebar.write(f"æ•°æ®ç”Ÿæˆæ—¶é—´ï¼š{stats['generation_date']}")
    
    # æ·»åŠ æ•°æ®æ¥æºä¿¡æ¯
    st.sidebar.subheader("æ•°æ®æ¥æº")
    st.sidebar.write(f"åŸå§‹æ•°æ®ç›®å½•ï¼š{DATA_DIR}")
    st.sidebar.write(f"å¤„ç†åæ•°æ®ç›®å½•ï¼š{PROCESSED_DATA_DIR}")
    
    # æ·»åŠ æ•°æ®ç»Ÿè®¡ä¿¡æ¯
    st.sidebar.subheader("æ•°æ®ç»Ÿè®¡")
    st.sidebar.write(f"æ€»è¿‡æ»¤åè¯æ•°ï¼š{stats['total_filtered_tokens']}")
    st.sidebar.write(f"å¹³å‡è¿‡æ»¤åè¯æ•°ï¼š{stats['total_filtered_tokens'] / stats['total_documents']:.2f}") 