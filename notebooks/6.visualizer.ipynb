{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1ae8281",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "可视化模块：将分析结果以图形方式展示\n",
    "\"\"\"\n",
    "\n",
    "from config import RESULTS_DIR, VISUALIZATION_CONFIG\n",
    "from datetime import datetime\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.cm as cm\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import logging\n",
    "from typing import *\n",
    "matplotlib.use('Agg')  # 设置后端为Agg，不显示图形窗口\n",
    "logger = logging.getLogger('Visualizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13800d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataVisualizer:\n",
    "    \"\"\"数据可视化类，负责生成各种可视化图表\"\"\"\n",
    "\n",
    "    def __init__(self, results_file_path=None):\n",
    "        \"\"\"初始化可视化器\"\"\"\n",
    "        self.results_dir = RESULTS_DIR\n",
    "\n",
    "        # 如果传入了分析结果，则使用传入的结果\n",
    "        results_file_path = results_file_path or os.path.join(\n",
    "            self.results_dir, \"analysis_results.json\")\n",
    "\n",
    "        self.analysis_results = self._load_analysis_results(\n",
    "            analysis_json_path=results_file_path)\n",
    "\n",
    "        if not self.analysis_results:\n",
    "            logger.error(\"无法获取分析结果，无法生成可视化\")\n",
    "            return {}\n",
    "\n",
    "        # 绘图参数\n",
    "        plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "        # 确保可视化目录存在\n",
    "        self.viz_dir = os.path.join(self.results_dir, \"visualizations\")\n",
    "        os.makedirs(self.viz_dir, exist_ok=True)\n",
    "\n",
    "        # 设置字体\n",
    "        plt.rcParams['font.family'] = VISUALIZATION_CONFIG['font_family']\n",
    "\n",
    "        if os.path.exists(VISUALIZATION_CONFIG['font_path']):\n",
    "            self.font_path = VISUALIZATION_CONFIG['font_path']\n",
    "        else:\n",
    "            logger.info(f\"字体{VISUALIZATION_CONFIG['font_path']} 不存在，回退至默认字体\")\n",
    "\n",
    "        # 设置颜色方案\n",
    "        self.colors = {\n",
    "            'france': VISUALIZATION_CONFIG['colors']['france'],  # 法国蓝\n",
    "            'china': VISUALIZATION_CONFIG['colors']['china'],    # 中国红\n",
    "        }\n",
    "\n",
    "    def visualize_all(self):\n",
    "        \"\"\"生成所有可视化\"\"\"\n",
    "        logger.info(\"开始生成所有可视化\")\n",
    "\n",
    "        # 生成词云\n",
    "        word_cloud_results = self.generate_word_clouds()\n",
    "\n",
    "        # 生成主题模型可视化\n",
    "        topic_results = self.generate_topic_visualizations()\n",
    "\n",
    "        # 生成文化维度雷达图\n",
    "        # culture_results = self.generate_cultural_radar_charts()\n",
    "\n",
    "        # 组合结果\n",
    "        visualization_results = {\n",
    "            'word_clouds': word_cloud_results,\n",
    "            'topic_visualizations': topic_results,\n",
    "            # 'cultural_radar_charts': culture_results,\n",
    "            'visualization_date': datetime.now().isoformat()\n",
    "        }\n",
    "\n",
    "        # 保存可视化结果\n",
    "        self._save_visualization_results(visualization_results)\n",
    "\n",
    "        logger.info(\"所有可视化生成完成\")\n",
    "\n",
    "        return visualization_results\n",
    "\n",
    "    def _load_analysis_results(self, analysis_json_path=None):\n",
    "        \"\"\"加载分析结果\"\"\"\n",
    "        if analysis_json_path is None:\n",
    "            results_file = os.path.join(\n",
    "                self.results_dir, \"analysis_results.json\")\n",
    "        else:\n",
    "            results_file = analysis_json_path\n",
    "\n",
    "        if not os.path.exists(results_file):\n",
    "            logger.warning(f\"分析结果文件不存在: {results_file}\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            with open(results_file, 'r', encoding='utf-8') as f:\n",
    "                results = json.load(f)\n",
    "            logger.info(\"成功加载分析结果\")\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            logger.error(f\"加载分析结果时出错: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def _save_visualization_results(self, results):\n",
    "        \"\"\"保存可视化结果\"\"\"\n",
    "        results_file = os.path.join(\n",
    "            self.results_dir, \"visualization_results.json\")\n",
    "\n",
    "        try:\n",
    "            with open(results_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "            logger.info(f\"可视化结果已保存至: {results_file}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"保存可视化结果时出错: {str(e)}\")\n",
    "\n",
    "    def load_visualization_results(self):\n",
    "        \"\"\"从文件加载可视化结果\"\"\"\n",
    "        logger.info(\"从文件加载可视化结果\")\n",
    "\n",
    "        results_file = os.path.join(\n",
    "            self.results_dir, \"visualization_results.json\")\n",
    "\n",
    "        if not os.path.exists(results_file):\n",
    "            raise FileNotFoundError(\n",
    "                f\"可视化结果文件不存在: {results_file}\")\n",
    "            \n",
    "        with open(results_file, 'r', encoding='utf-8') as f:\n",
    "            results = json.load(f)\n",
    "        logger.info(f\"成功加载可视化结果\")\n",
    "        \n",
    "    def generate_word_clouds(self):\n",
    "        \"\"\"生成词云可视化\"\"\"\n",
    "        logger.info(\"生成词云可视化\")\n",
    "        results = {}\n",
    "\n",
    "        if 'tf_idf' not in self.analysis_results:\n",
    "            logger.warning(\"找不到TF-IDF分析结果，无法生成词云\")\n",
    "            return results\n",
    "\n",
    "        tf_idf_results = self.analysis_results['tf_idf']\n",
    "\n",
    "        for country in tf_idf_results.keys():\n",
    "            country_dir = os.path.join(self.viz_dir, country)\n",
    "            if not os.path.exists(country_dir):\n",
    "                os.makedirs(country_dir)\n",
    "\n",
    "            results[country] = {}\n",
    "\n",
    "            for sector, sector_data in tf_idf_results[country].items():\n",
    "                logger.info(f\"生成{country}的{sector}领域词云\")\n",
    "\n",
    "                if 'top_words' not in sector_data or not sector_data['top_words']:\n",
    "                    logger.warning(f\"{country}的{sector}领域没有词频数据\")\n",
    "                    continue\n",
    "\n",
    "                # 创建词-权重字典\n",
    "                word_weights = {item['word']: item['score']\n",
    "                                for item in sector_data['top_words']}\n",
    "\n",
    "                # 设置词云颜色\n",
    "                color = self.colors[country]\n",
    "\n",
    "                # 创建词云对象\n",
    "                wc = WordCloud(\n",
    "                    width=800,\n",
    "                    height=400,\n",
    "                    background_color='white',\n",
    "                    colormap='Blues' if country == 'france' else 'Reds',\n",
    "                    max_words=100,\n",
    "                    contour_width=1,\n",
    "                    contour_color='steelblue' if country == 'france' else 'firebrick',\n",
    "                    font_path=self.font_path)\n",
    "\n",
    "                # 生成词云\n",
    "                wc.generate_from_frequencies(word_weights)\n",
    "\n",
    "                # 创建图形\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.imshow(wc, interpolation='bilinear')\n",
    "                plt.axis('off')\n",
    "                plt.title(\n",
    "                    f\"{country.capitalize()} - {sector.capitalize()} Sector\", fontsize=16)\n",
    "                plt.tight_layout()\n",
    "\n",
    "                # 保存图像\n",
    "                output_path = os.path.join(\n",
    "                    country_dir, f\"wordcloud_{sector}.svg\")\n",
    "                plt.savefig(output_path, dpi=300, bbox_inches='tight', format='svg')\n",
    "                plt.close('all')  # 确保关闭所有图形\n",
    "\n",
    "                results[country][sector] = output_path\n",
    "\n",
    "        logger.info(\"词云可视化生成完成\")\n",
    "\n",
    "        return results\n",
    "\n",
    "    def generate_topic_visualizations(self):\n",
    "        \"\"\"生成主题模型可视化\"\"\"\n",
    "        logger.info(\"生成主题模型可视化\")\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        if 'topics' not in self.analysis_results:\n",
    "            logger.warning(\"找不到主题分析结果，无法生成可视化\")\n",
    "            return results\n",
    "\n",
    "        topic_results = self.analysis_results['topics']\n",
    "\n",
    "        for country in topic_results.keys():\n",
    "            country_dir = os.path.join(self.viz_dir, country)\n",
    "            if not os.path.exists(country_dir):\n",
    "                os.makedirs(country_dir)\n",
    "\n",
    "            results[country] = {}\n",
    "\n",
    "            for sector, sector_data in topic_results[country].items():\n",
    "                logger.info(f\"生成{country}的{sector}领域主题可视化\")\n",
    "\n",
    "                if 'topics' not in sector_data or not sector_data['topics']:\n",
    "                    logger.warning(f\"{country}的{sector}领域没有主题数据\")\n",
    "                    continue\n",
    "\n",
    "                topics = sector_data['topics']\n",
    "\n",
    "                # 创建多个子图\n",
    "                n_topics = len(topics)\n",
    "                fig, axes = plt.subplots(1, n_topics, figsize=(n_topics*4, 5))\n",
    "\n",
    "                # 如果只有一个主题，将axes转换为列表\n",
    "                if n_topics == 1:\n",
    "                    axes = [axes]\n",
    "\n",
    "                # 设置颜色映射\n",
    "                cmap = cm.get_cmap('Blues' if country == 'france' else 'Reds')\n",
    "                norm = Normalize(vmin=0, vmax=max(\n",
    "                    [max(topic['weights']) for topic in topics]))\n",
    "\n",
    "                # 绘制每个主题的词条形图\n",
    "                for i, topic in enumerate(topics):\n",
    "                    words = topic['words']\n",
    "                    weights = topic['weights']\n",
    "\n",
    "                    # 对权重和词组合排序\n",
    "                    word_weight_pairs = list(zip(words, weights))\n",
    "                    word_weight_pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "                    words = [pair[0] for pair in word_weight_pairs]\n",
    "                    weights = [pair[1] for pair in word_weight_pairs]\n",
    "\n",
    "                    # 反转顺序，使最重要的词在顶部\n",
    "                    words = words[:10]\n",
    "                    weights = weights[:10]\n",
    "                    words.reverse()\n",
    "                    weights.reverse()\n",
    "\n",
    "                    # 绘制水平条形图\n",
    "                    colors = [cmap(norm(weight)) for weight in weights]\n",
    "                    axes[i].barh(words, weights, color=colors)\n",
    "\n",
    "                    # 设置标题和标签\n",
    "                    axes[i].set_title(f\"Topic {i+1}\", fontsize=14)\n",
    "                    axes[i].set_xlabel('Weight', fontsize=12)\n",
    "\n",
    "                    # 添加格线\n",
    "                    axes[i].grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "                # 调整布局\n",
    "                plt.suptitle(\n",
    "                    f\"{country.capitalize()} - {sector.capitalize()} Sector: Topic Model\", fontsize=16)\n",
    "                plt.tight_layout()\n",
    "\n",
    "                # 保存图像\n",
    "                output_path = os.path.join(country_dir, f\"topics_{sector}.svg\")\n",
    "                plt.savefig(output_path, dpi=300, bbox_inches='tight', format='svg')\n",
    "                plt.close('all')  # 确保关闭所有图形\n",
    "\n",
    "                results[country][sector] = output_path\n",
    "\n",
    "        logger.info(\"主题模型可视化生成完成\")\n",
    "\n",
    "        return results\n",
    "\n",
    "    # def generate_cultural_radar_charts(self):\n",
    "    #     \"\"\"生成文化维度雷达图\"\"\"\n",
    "    #     logger.info(\"生成文化维度雷达图\")\n",
    "\n",
    "    #     results = {}\n",
    "\n",
    "    #     if 'cultural_dimensions' not in self.analysis_results:\n",
    "    #         logger.warning(\"找不到文化维度分析结果，无法生成雷达图\")\n",
    "    #         return results\n",
    "\n",
    "    #     cultural_results = self.analysis_results['cultural_dimensions']\n",
    "\n",
    "    #     # 准备数据\n",
    "    #     countries = list(cultural_results.keys())\n",
    "\n",
    "    #     if not countries:\n",
    "    #         logger.warning(\"没有国家数据\")\n",
    "    #         return results\n",
    "\n",
    "    #     # 创建雷达图数据\n",
    "    #     fig = go.Figure()\n",
    "\n",
    "    #     for country in countries:\n",
    "    #         # 获取维度分数和维度名称\n",
    "    #         dimensions = cultural_results[country].keys()\n",
    "    #         scores = [cultural_results[country][dim]['avg_value']\n",
    "    #                   for dim in dimensions]\n",
    "\n",
    "    #         # 闭合雷达图\n",
    "    #         scores.append(scores[0])\n",
    "    #         dimensions_closed = list(dimensions) + [list(dimensions)[0]]\n",
    "\n",
    "    #         # 添加轨迹\n",
    "    #         fig.add_trace(go.Scatterpolar(\n",
    "    #             r=scores,\n",
    "    #             theta=dimensions_closed,\n",
    "    #             fill='toself',\n",
    "    #             name=country.capitalize(),\n",
    "    #             line_color=self.colors[country]\n",
    "    #         ))\n",
    "\n",
    "    #     # 更新布局\n",
    "    #     fig.update_layout(\n",
    "    #         polar=dict(\n",
    "    #             radialaxis=dict(\n",
    "    #                 visible=True,\n",
    "    #                 range=[-1, 1]\n",
    "    #             )\n",
    "    #         ),\n",
    "    #         title=\"Cultural Dimensions: France vs China\",\n",
    "    #         showlegend=True\n",
    "    #     )\n",
    "\n",
    "    #     # 保存图像\n",
    "    #     output_path = os.path.join(\n",
    "    #         self.viz_dir, \"cultural_dimensions_radar.html\")\n",
    "    #     fig.write_html(output_path)\n",
    "\n",
    "    #     # 也保存为图像\n",
    "    #     # img_path = os.path.join(self.viz_dir, \"cultural_dimensions_radar.png\")\n",
    "    #     # fig.write_image(img_path, width=800, height=600, scale=2)\n",
    "\n",
    "    #     results['radar_chart'] = output_path\n",
    "    #     # results['radar_image'] = img_path\n",
    "\n",
    "    #     logger.info(\"文化维度雷达图生成完成\")\n",
    "\n",
    "    #     return results\n",
    "\n",
    "    def generate_cultural_radar_charts(self, save_path: str = None):\n",
    "        \"\"\"\n",
    "        用 matplotlib 画出中法文化维度雷达图\n",
    "        :param cultural_results: dict 格式，如 analysis_results[\"cultural_dimensions\"]\n",
    "        :param save_path: 保存路径，如 \"results/cultural_dimensions_radar.png\"\n",
    "        \"\"\"\n",
    "        cultural_results = self.analysis_results[\"cultural_dimensions\"]\n",
    "        if not cultural_results:\n",
    "            logger.warning(\"没有文化维度数据\")\n",
    "            return {}\n",
    "        labels = list(cultural_results[\"china\"].keys())\n",
    "        china_scores = [cultural_results[\"china\"][dim][\"avg_value\"] for dim in labels]\n",
    "        france_scores = [cultural_results[\"france\"][dim][\"avg_value\"] for dim in labels]\n",
    "\n",
    "        # 闭环\n",
    "        labels += [labels[0]]\n",
    "        china_scores += [china_scores[0]]\n",
    "        france_scores += [france_scores[0]]\n",
    "\n",
    "        angles = np.linspace(0, 2 * np.pi, len(labels), endpoint=True)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 6), subplot_kw=dict(polar=True))\n",
    "        ax.plot(angles, china_scores, label=\"China\", linewidth=2)\n",
    "        ax.fill(angles, china_scores, alpha=0.25)\n",
    "\n",
    "        ax.plot(angles, france_scores, label=\"France\", linewidth=2)\n",
    "        ax.fill(angles, france_scores, alpha=0.25)\n",
    "\n",
    "        ax.set_thetagrids(angles * 180 / np.pi, labels)\n",
    "        ax.set_title(\"中法文化维度投影对比\", fontsize=14)\n",
    "        ax.legend(loc=\"upper right\", bbox_to_anchor=(1.2, 1.1))\n",
    "        ax.set_rlabel_position(0)\n",
    "        ax.grid(True)\n",
    "\n",
    "        # 设置坐标范围适应你现在的数据范围 [-0.1, 0.1]\n",
    "        ax.set_ylim(-0.1, 0.1)\n",
    "\n",
    "        # 保存图像\n",
    "        output_path = os.path.join(self.viz_dir, f\"cultural_dimensions.svg\")\n",
    "        plt.savefig(output_path, dpi=300, bbox_inches='tight', format='svg')\n",
    "        plt.close('all')  # 确保关闭所有图形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e28dbcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文化维度解释\n",
    "HOFSTEDE_DESCRIPTIONS = {\n",
    "    \"power_distance\": \"权力距离：社会中权力的不平等分配的接受程度\",\n",
    "    \"individualism\": \"个人主义：个人对团体的独立程度\",\n",
    "    \"masculinity\": \"男性气质：成就、英雄主义、果断和物质成功的偏好\",\n",
    "    \"uncertainty_avoidance\": \"不确定性规避：社会对不确定性和模糊性的不适程度\",\n",
    "    \"long_term_orientation\": \"长期导向：注重长期规划和传统的程度\",\n",
    "    \"indulgence\": \"放纵度：控制自身欲望和冲动的程度\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27d54e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = DataVisualizer()\n",
    "visualization_results = visualizer.visualize_all()\n",
    "print(\"可视化结果：\", visualization_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9752ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
