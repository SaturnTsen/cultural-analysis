{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97f73e7d",
   "metadata": {},
   "source": [
    "## Util: Text cleaner\n",
    "\n",
    "This notebook helps to clean the text data for further analysis. It uses chuking and LLM to clean the data.\n",
    "\n",
    "1. Remove irrelevant content such as tables of contents, headers, footers, and page numbers;\n",
    "2. Remove meaningless isolated numbers;\n",
    "3. Retain only complete Chinese, French or English sentences, each on a new line, ending with a period;\n",
    "4. Do not insert line breaks in the middle of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616f70dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "class TextCleaner:\n",
    "    def __init__(self,\n",
    "                 base_url=\"https://api.siliconflow.cn/v1\",\n",
    "                 model_name=\"Pro/deepseek-ai/DeepSeek-V3\",\n",
    "                 max_chars_per_request=8000, batch_size=50):\n",
    "        self.client = openai.OpenAI(\n",
    "            api_key=os.environ.get(\"DEEPSEEK_API_KEY\"),\n",
    "            base_url=base_url\n",
    "        )\n",
    "        self.model_name = model_name\n",
    "        self.max_chars_per_request = max_chars_per_request\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def _split_text(self, text):\n",
    "        \"\"\"Ë∂ÖÈïøÊñáÊú¨ÂàáÁâá\"\"\"\n",
    "        return [text[i:i+self.max_chars_per_request] for i in range(0, len(text), self.max_chars_per_request)]\n",
    "\n",
    "    def _stream_clean_chunk(self, text_chunk):\n",
    "        \"\"\"Stream clean a single small text chunk\"\"\"\n",
    "        prompt = f\"\"\"Please clean the following text according to these rules:\n",
    "    1. Remove irrelevant content such as tables of contents, headers, footers, and page numbers;\n",
    "    2. Remove meaningless isolated numbers;\n",
    "    3. Retain only complete Chinese, French or English sentences, each on a new line, ending with a period;\n",
    "    4. Do not insert line breaks in the middle of sentences.\n",
    "\n",
    "    Here is the raw text to be cleaned:\n",
    "    {text_chunk}\n",
    "    \"\"\"\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        for chunk in response:\n",
    "            if chunk.choices[0].delta.content:\n",
    "                yield chunk.choices[0].delta.content\n",
    "\n",
    "    def clean_and_save(self, text: str, output_path: str):\n",
    "        # print(text)\n",
    "        \"\"\"‰ΩøÁî®Â§öÁ∫øÁ®ãÊ∏ÖÊ¥óÊñáÊú¨Âπ∂‰øùÂ≠ò\"\"\"\n",
    "        text_chunks = self._split_text(text)\n",
    "        id = output_path.split('/')[-1].split('.')[0]\n",
    "        print(f\"Ê≠£Âú®Ê∏ÖÊ¥óÊñáÊú¨{id}ÔºåÂàÜ‰∏∫ {len(text_chunks)} ÊÆµ...\")\n",
    "\n",
    "        def clean_chunk(index, chunk_text):\n",
    "            buffer = []\n",
    "            for delta in self._stream_clean_chunk(chunk_text):\n",
    "                buffer.append(delta)\n",
    "            return index, ''.join(buffer)  # ‰øùÁïôÂéüÂßãÈ°∫Â∫è\n",
    "\n",
    "        cleaned_chunks = [None] * len(text_chunks)  # ‰øùÁïôÁªìÊûú‰ΩçÁΩÆ\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=32) as executor:\n",
    "            futures = {executor.submit(clean_chunk, idx, chunk): idx for idx, chunk in enumerate(text_chunks)}\n",
    "            for future in tqdm(as_completed(futures), total=len(futures), desc=\"Ê∏ÖÊ¥óËøõÂ∫¶\"):\n",
    "                idx, cleaned_text = future.result()\n",
    "                cleaned_chunks[idx] = cleaned_text\n",
    "\n",
    "        print(output_path)    \n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f_out:\n",
    "            buffer = []\n",
    "            for cleaned_text in cleaned_chunks:\n",
    "                buffer.append(cleaned_text)\n",
    "                if len(buffer) >= self.batch_size:\n",
    "                    f_out.write(''.join(buffer))\n",
    "                    f_out.flush()\n",
    "                    buffer.clear()\n",
    "\n",
    "            if buffer:\n",
    "                f_out.write(''.join(buffer))\n",
    "                f_out.flush()\n",
    "\n",
    "        print(f\"\\n‚úÖ Â∑≤‰øùÂ≠òÂà∞: {output_path}\")\n",
    "        \n",
    "def batch_clean_texts(text_cleaner: TextCleaner, raw_text_list, output_list, max_workers=15):\n",
    "    \"\"\"ÊâπÈáèÂπ∂ÂèëÊ∏ÖÊ¥óÔºåÁî±Â§ñÈÉ®ÊéßÂà∂\"\"\"\n",
    "    def worker(text, output_path):\n",
    "        try:\n",
    "            text_cleaner.clean_and_save(text, output_path)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Â§ÑÁêÜÂ§±Ë¥•: {output_path}ÔºåÈîôËØØÔºö{e}\")\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for text, output_path in zip(raw_text_list, output_list):\n",
    "            futures.append(executor.submit(worker, text, output_path))\n",
    "\n",
    "        for _ in tqdm(as_completed(futures), total=len(futures), desc=\"Processing files\"):\n",
    "            pass\n",
    "\n",
    "    print(\"\\n‚úÖ ÊâÄÊúâÊñá‰ª∂Â§ÑÁêÜÂÆåÊØïÔºÅ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dc5fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "import os\n",
    "import re\n",
    "raw_path = \"path/to/your/raw/text/files\"  # Replace with your actual path\n",
    "output_path = \"path/to/your/output/files\"  # Replace with your actual path\n",
    "\n",
    "def natural_sort_key(s):\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "raw_filenames = sorted(\n",
    "    [filename for filename in os.listdir(raw_path)\n",
    "        if filename.endswith('.txt')\n",
    "        and not filename.startswith('cleaned_')\n",
    "        and not os.path.exists(os.path.join(output_path, f\"cleaned_{filename}\"))],\n",
    "    key=natural_sort_key\n",
    ")\n",
    "\n",
    "raw_text_list = []\n",
    "for filename in raw_filenames:\n",
    "    with open(os.path.join(raw_path, filename), 'r', encoding='utf-8') as f:\n",
    "        raw_text_list.append(f.read())\n",
    "        \n",
    "output_list = [os.path.join(output_path, f\"cleaned_{filename}\") for filename in raw_filenames]\n",
    "batch_clean_texts(TextCleaner(), raw_text_list, output_list, max_workers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee9931e",
   "metadata": {},
   "source": [
    "### Util: Translator\n",
    "\n",
    "This notebook helps to translate the text data for further analysis. It uses Standard OpenAI API to translate the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff083027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "import aiofiles\n",
    "from asyncio import Semaphore\n",
    "import openai\n",
    "from tqdm.asyncio import tqdm\n",
    "from config import BASE_URL, PAYLOAD_MODEL, API_KEY\n",
    "\n",
    "class AsyncTextTranslator:\n",
    "    def __init__(self,\n",
    "                 target_lang: str,\n",
    "                 base_url: str = BASE_URL,\n",
    "                 model_name: str = PAYLOAD_MODEL,\n",
    "                 max_chars_per_request: int = 2000,\n",
    "                 batch_size: int = 50,\n",
    "                 concurrency_limit: int = 100,\n",
    "                 timeout: int = 360):\n",
    "        self.client = openai.AsyncOpenAI(\n",
    "            api_key=API_KEY,\n",
    "            base_url=base_url\n",
    "        )\n",
    "        self.model_name = model_name\n",
    "        self.target_lang = target_lang\n",
    "        self.max_chars_per_request = max_chars_per_request\n",
    "        self.batch_size = batch_size\n",
    "        self.semaphore = Semaphore(concurrency_limit)\n",
    "        self.timeout = timeout\n",
    "\n",
    "    def _split_text(self, text: str) -> List[str]:\n",
    "        return [text[i:i + self.max_chars_per_request] for i in range(0, len(text), self.max_chars_per_request)]\n",
    "\n",
    "    async def _safe_stream_translate_chunk(self, chunk_text: str) -> str:\n",
    "        try:\n",
    "            return await asyncio.wait_for(self._stream_translate_chunk(chunk_text), timeout=self.timeout)\n",
    "        except asyncio.TimeoutError:\n",
    "            print(f\"[‚è∞ Timeout] Chunk exceeded {self.timeout}s\")\n",
    "            return \"[Translation Timeout]\"\n",
    "        except Exception as e:\n",
    "            print(f\"[‚ùå Error] Chunk failed: {e}\")\n",
    "            return \"[Translation Error]\"\n",
    "\n",
    "    async def _stream_translate_chunk(self, text_chunk: str) -> str:\n",
    "        system_prompt = (\n",
    "            f\"You are a translation engine. \"\n",
    "            f\"Translate all input to {self.target_lang}. Keep format, do not add extra content.\"\n",
    "        )\n",
    "        async with self.semaphore:\n",
    "            # print(f\"[üí¨] Ê≠£Âú®ÁøªËØë: {text_chunk[:20]}...\")\n",
    "            response = await self.client.chat.completions.create(\n",
    "                model=self.model_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": text_chunk}\n",
    "                ],\n",
    "                temperature=0.0,\n",
    "                stream=True\n",
    "            )\n",
    "            buffer = []\n",
    "            async for chunk in response:\n",
    "                if chunk.choices[0].delta.content:\n",
    "                    buffer.append(chunk.choices[0].delta.content)\n",
    "            return ''.join(buffer)\n",
    "\n",
    "    async def translate_and_save(self, text_path: Path, output_path: Path = None):\n",
    "        async with aiofiles.open(text_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f_in:\n",
    "            text = await f_in.read()\n",
    "        text_chunks = self._split_text(text)\n",
    "        if output_path is None:\n",
    "            output_path = text_path.with_suffix('.translated.txt')\n",
    "            print(f\"[üìÅ] ÁøªËØëÊñá‰ª∂: {output_path.stem}\")\n",
    "\n",
    "        coroutines = [self._safe_stream_translate_chunk(\n",
    "            chunk) for chunk in text_chunks]\n",
    "        translated_chunks = await tqdm.gather(*coroutines, desc=f\"ÁøªËØëËøõÂ∫¶: {text_path.stem}\")\n",
    "\n",
    "        async with aiofiles.open(output_path, \"w\", encoding=\"utf-8\") as f_out:\n",
    "            buffer = []\n",
    "            for chunk in translated_chunks:\n",
    "                buffer.append(chunk)\n",
    "                if len(buffer) >= self.batch_size:\n",
    "                    await f_out.write(''.join(buffer))\n",
    "                    await f_out.flush()\n",
    "                    buffer.clear()\n",
    "            if buffer:\n",
    "                await f_out.write(''.join(buffer))\n",
    "                await f_out.flush()\n",
    "\n",
    "        # print(f\"‚úÖ Â∑≤‰øùÂ≠òËá≥: {output_path}\")\n",
    "\n",
    "    async def translate_all(self, text_paths: List[Path]):\n",
    "        results = await asyncio.gather(\n",
    "            *(self.translate_and_save(path) for path in text_paths),\n",
    "            return_exceptions=True\n",
    "        )\n",
    "        for r in results:\n",
    "            if isinstance(r, Exception):\n",
    "                print(\"[‚ùå]\", repr(r))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
